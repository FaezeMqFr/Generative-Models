# Generative-Models
Code and explanation for the Generating Models
Generative models revolutionized machine learning by allowing computers to create new data instances that look like training data. Models like these are critical to a wide range of applications, including image synthesis, speech synthesis, and data augmentation, contributing significantly to AI advances. The most popular generative models are Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). Each offers unique approaches to generating data and learning representations.
The Variational Autoencoder uses Bayesian inference to generate data samples by learning the distribution of input data. VAEs are good at learning efficient data encodings and generating new points from the latent space, making them useful for generating data and compressing data.
On the other hand, generative adversarial networks employ a game-theoretic approach in which two models are simultaneously trained in a competitive manner, such that a generator and a discriminator are both trained simultaneously according to their relative strengths. As a general rule, it is the goal of a generator to produce data that is indistinguishable from real data, whereas the goal of a discriminator is to distinguish between real and generated data. Through the use of adversarial training, GANs have been able to generate high-quality, realistic images and have been applied in the field of image synthesis, super-resolution, and many more.
In this report, the objectives are to implement and analyze both VAEs and GANs on the datasets MNIST and CIFAR-10, to investigate the structural intricacies, training dynamics, as well as the quality of the generated samples of each model. CIFAR-10 and MNIST are two of the most important datasets in machine learning, especially for benchmarking algorithms in image recognition and computer vision. Researchers can compare the effectiveness of different algorithms under similar conditions by evaluating the performance of different datasets.
MNIST Dataset with Full Name: Modified National Institute of Standards and Technology dataset has 70,000 grayscale images of handwritten digits (0-9). There are 60,000 training images and 10,000 test images in the dataset. Each image is 28x28 pixels.
CIFAR-10 Dataset with Full Name: Canadian Institute For Advanced Research (CIFAR)-10 dataset consists of 60,000 32x32 color images in 10 different classes, including airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 50,000 training images and 10,000 testing images, each with 6,000 images. The framework I used for this assignment were Tensorflow for VAE and pytorch for GANs. Also, I used Google colab for this assignment. 
